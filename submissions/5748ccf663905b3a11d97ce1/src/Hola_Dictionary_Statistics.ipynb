{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import json\n",
    "import Hola_Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Hola_Reverse_Sequence_Representer():\n",
    "    def get_alphabet(self):\n",
    "        return \"abcdefghijklmnopqrstuvwxyz'$\"\n",
    "\n",
    "    def get_offset(self, reversed_seq):\n",
    "        alphabet = self.get_alphabet()\n",
    "        l = len(alphabet)\n",
    "        order = len(reversed_seq)\n",
    "        pos = 0\n",
    "        for i in range(0, order):\n",
    "            sym = reversed_seq[i]\n",
    "            sym_pos = alphabet.index(sym)\n",
    "            pos += sym_pos * (l ** (order - i - 1))\n",
    "        return pos\n",
    "\n",
    "    def get_root_subchain(self, root, order = 3):\n",
    "        alphabet = self.get_alphabet()\n",
    "        l = len(alphabet)\n",
    "        start = alphabet.index(root) * (l ** (order-1))\n",
    "        stop = (alphabet.index(root) + 1) * (l ** (order-1))\n",
    "        return start, stop\n",
    "    \n",
    "    def parse_word(self, word, order = 3):\n",
    "        reversed_seq = []\n",
    "        root = '$'\n",
    "        for i in range(1, len(word)):\n",
    "            sub_seq = [root]\n",
    "            for j in range(0, order-1):\n",
    "                if i + j > len(word):\n",
    "                    sub_seq.append('$')\n",
    "                else:\n",
    "                    sub_seq.append(word[-i-j])\n",
    "            branch = word[-i]\n",
    "            nest = word[-i-1]\n",
    "            reversed_seq.append(sub_seq)\n",
    "            root = word[-i]\n",
    "        return reversed_seq\n",
    "    \n",
    "#representer = Hola_Reverse_Sequence_Representer()\n",
    "#print representer.parse_word('xyz', 3)\n",
    "#print representer.get_offset(['$','$','$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Hola_Dictionary_Statistics():\n",
    "    _dict = None\n",
    "    \n",
    "    def __init__(self, hola_dictionary):\n",
    "        self._dict = hola_dictionary\n",
    "        \n",
    "    def _get_length_distribution(self):\n",
    "        distrib = {}\n",
    "        for word in self._dict.get_words():\n",
    "            length = len(word)\n",
    "            freq = distrib.get(length, 0)\n",
    "            distrib[length] = freq + 1\n",
    "    \n",
    "        total = sum(distrib.values())\n",
    "        return {key: float(distrib[key]) / total for key in distrib}\n",
    "        \n",
    "        \n",
    "    def get_significant_length(self, percentile, with_frequency=False):\n",
    "        distrib = self._get_length_distribution()\n",
    "        sorted_distrib = sorted(distrib.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        values = []\n",
    "        accumulate = 0\n",
    "        for key, p in sorted_distrib:\n",
    "            if accumulate + p <= percentile:\n",
    "                if with_frequency:\n",
    "                    values.append((key, p, accumulate + p))\n",
    "                else:\n",
    "                    values.append(key)\n",
    "            accumulate += p\n",
    "        return values\n",
    "    \n",
    "    \n",
    "#dict_eng = Hola_Dictionary.Hola_Dictionary_English()\n",
    "#dict_eng.read('words.txt')\n",
    "#stat_eng = Hola_Dictionary_Statistics(dict_eng)\n",
    "#print stat.get_significant_length(0.99, True)\n",
    "#print stat_eng.get_significant_length(0.99)\n",
    "\n",
    "#import Hola_Test_System\n",
    "#test_system = Hola_Test_System.Hola_Test_System()\n",
    "#dict_stop = Hola_Dictionary.Hola_Dictionary_Stop(test_system)\n",
    "#dict_stop.read(15, 50)\n",
    "#stat_stop = Hola_Dictionary_Statistics(dict_stop)\n",
    "#print stat_stop.get_significant_length(0.99, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0.00045, 0.00357, 0.00836, 0.0017, 0.00157, 0.011, 0.00075]\n"
     ]
    }
   ],
   "source": [
    "class Hola_Dictionary_Markov_Chain():\n",
    "    _dict = None\n",
    "    _order = 3\n",
    "    _chain = []\n",
    "    _representer = None\n",
    "    _sign_len = None\n",
    "    \n",
    "    def __init__(self, hola_dictionary, order = 3):\n",
    "        self._dict = hola_dictionary\n",
    "        self._order = order\n",
    "        self._representer = Hola_Reverse_Sequence_Representer()\n",
    "        \n",
    "    def train(self, significant_length_percentile = 0.99):\n",
    "        self._chain = [0] * pow(len(self._representer.get_alphabet()), self._order)\n",
    "        stat = Hola_Dictionary_Statistics(self._dict)\n",
    "        self._sign_len = stat.get_significant_length(significant_length_percentile)\n",
    "        \n",
    "        for word in self._dict.get_words():\n",
    "            if len(word) not in self._sign_len:\n",
    "                continue\n",
    "            for reversed_seq in self._representer.parse_word(word, self._order):\n",
    "                offset = self._representer.get_offset(reversed_seq)\n",
    "                self._chain[offset] = self._chain[offset] + 1\n",
    "                \n",
    "        for root in self._representer.get_alphabet():\n",
    "            subchain_start, subchain_stop = self._representer.get_root_subchain(root, self._order)\n",
    "            subchain = self._chain[subchain_start:subchain_stop]\n",
    "            total = sum(subchain)\n",
    "            for i in range(subchain_start, subchain_stop):\n",
    "                if total == 0:\n",
    "                    self._chain[i] = 0\n",
    "                else:\n",
    "                    self._chain[i] = self._chain[i] / float(total)\n",
    "        formatter = lambda f: 0 if f == 0 else round(f*100, 3)\n",
    "        self._chain = [formatter(f) for f in self._chain]\n",
    "                \n",
    "    def save_to_file(self, file_name):\n",
    "        f = open(file_name, 'w+')\n",
    "        f.write(json.dumps(self._chain))\n",
    "        f.close()\n",
    "        \n",
    "    def test(self, word):\n",
    "        if len(word) not in self._sign_len:\n",
    "            return [0] * len(self._representer.parse_word(word, self._order))\n",
    "        plist = []\n",
    "        for reversed_seq in self._representer.parse_word(word, self._order):\n",
    "            offset = self._representer.get_offset(reversed_seq)\n",
    "            plist.append(self._chain[offset])\n",
    "        return plist\n",
    "            \n",
    "        \n",
    "\n",
    "#chain = Hola_Dictionary_Markov_Chain(dict_eng, 3)\n",
    "#chain.train(0.99)\n",
    "#chain.save_to_file('mc_eng_3.json')\n",
    "#print chain.test('ignewutkgnjndgusdgudigjidgdshghdjgodgjig')\n",
    "#print chain.test('krakatau')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
